tags:
  authentication: true
  logs: true
  notifications: true

global:
  # Deployment Configuration
  #   Description: This section allows you to configure global settings for the Accelleran deployment.
  #
  #   Parameters:
  #     - `deploymentId`: Required: Represents the name of the Accelleran deployment. This value will be included
  #                       as a label in generated notifications and should be unique for each deployment.
  #
  #   Value types:
  #     - deploymentId: string
  #
  deploymentId: ""

  # Kubernetes advertise IP
  #   Description:  Supply the Kubernetes Advertise address of your Kubernetes cluster.
  #                 This is used by some services that are exposed via a nodePort.
  #
  #   Value type:   string
  #
  kubeIp: "10.20.20.20"
  # dRAX IP address
  #   Description:  REQUIRED
  #                 Supply the IP address to access dRAX.
  #                 The IP address should be unique to dRAX,
  #                 so for example the `kubeIp` can't be (re)used here.
  #                 Also the used service loadbalancer (e.g. metallb or kube-vip)
  #                 should be allowed to use this IP address.
  #                 This may require additional configuration there.
  #
  #   Value type:   string
  #   Example:      10.1.2.3
  ipAddress: ""
  # dRAX domain name
  #   Description:  Optionally, supply the domain name to access dRAX.
  #                 It should be setup externally to resolve to the dRAX IP address.
  #
  #   Value type:   string
  #   Example:      drax.accelleran.com
  domain: ""

  # 4G/5G Options
  #   Description:  Depending on the product bought, you may enable or disable the accompanying features.
  #
  #   Value type:   bool
  #
  enable4G: false
  enable5G: true

  # Accelleran License
  #   Description:  In order to use the Accelleran products, you need to have a license from Accelleran.
  #                 Please contact Accelleran to get the license.
  #                 The license file should be saved as a Kubernetes secret. The name of the secret should be
  #                 supplied here under the "secretName" field.
  #                 To create the secret you can use the following command:
  #                 kubectl create secret generic accelleran-license --from-file=license.crt
  #
  # Value type:     enabled: string
  #                 secretName: string
  #
  accelleranLicense:
    enabled: true

  # Accelleran Product Configuration
  #   Description:  This configuration field allows you to specify the product variant for Accelleran deployments.
  #
  #   The `accelleranProduct` parameter can be used to select between the following two products:
  #     - `P5G`: for configuring the Private 5G (P5G) product
  #     - `DRAX`: for configuring the DRAX product
  #
  #   Value type:   accelleranProduct: string
  #
  #   Accepted values:
  #     - "P5G" : Private 5G Product
  #     - "DRAX": DRAX Product
  #
  accelleranProduct: "P5G"

  # Alerting Configuration
  #   Description: This section allows you to configure the alerting settings for the Accelleran dRAX.
  #
  #   Parameters:
  #     - `enabled`:      A boolean flag to enable or disable alerting. When set to `true`, alerting is activated;
  #                       when set to `false`, alerts are not provisioned.
  #     - `slackToken`:   Required: The token used to configure the Slack contact point for alert notifications.
  #                       This token allows alerts to be sent via Slack.
  #     - `channel`:      Required: The Slack channel name or channel ID where alerts will be sent.
  #
  #   Value types:
  #     - enabled: boolean
  #     - slackToken: string
  #     - channel: string
  #
  alerting:
    enabled: false
    slackToken: ""
    channel: ""

  persistentLogLevel: info

  nodeSelector: {}


bootstrap:
  create: true
  name: "{{ $.Release.Name }}-bootstrap"
  redis:
    enabled: true
    hostname: ""
    port: 0
  nats:
    enabled: true
    hostname: ""
    port: 0
  kafka:
    enabled: true
    hostname: ""
    port: 0


drax:
  auth:
    superadminUser: "superadmin"
    superadminEmail: "support@accelleran.com"
    superadminPassword: ""

    adminUser: "admin"
    adminEmail: "drax@example.com"
    adminPassword: ""

    realm:
      name: "drax"
      displayName: "dRAX"

  service:
    enabled: true
    type: LoadBalancer
    loadBalancerIP: "{{ $.Values.global.ipAddress }}"
    ports:
      http:
        port: 80
        targetPort: http
        protocol: TCP
        appProtocol: http
      https:
        port: 443
        targetPort: https
        protocol: TCP
        appProtocol: https
      # nats:
      #   port: 4222
      #   targetPort: 4222
      #   protocol: TCP
      # kafka:
      #   port: 9092
      #   targetPort: 9092
      #   protocol: TCP

  wellKnownOpenidConfigurationIngress:
    enabled: true
    className: drax
    annotations:
      nginx.ingress.kubernetes.io/rewrite-target: "/keycloak/realms/{{ $.Values.drax.auth.realm.name }}/.well-known/openid-configuration"
      nginx.ingress.kubernetes.io/proxy-body-size: 30m
      nginx.ingress.kubernetes.io/proxy-buffer-size: 256k
      nginx.ingress.kubernetes.io/proxy-buffering: 'on'
      nginx.ingress.kubernetes.io/proxy-buffers-number: '4'
      nginx.ingress.kubernetes.io/proxy-max-temp-file-size: 1024m
    hosts:
      - paths:
          - path: /.well-known/openid-configuration
            pathType: ImplementationSpecific
            port: http
    tls: []

  keycloak-init:
    nameOverride: "keycloak-init"

    keycloakInitImage:
      repository: accelleran/acc-generic-img
      pullPolicy: IfNotPresent
      tag: "0.9.1"

    image:
      repository: accelleran/acc-generic-img
      pullPolicy: IfNotPresent
      tag: "0.9.1"

    imagePullSecrets:
      - name: accelleran-secret

    accelleranLicense:
      enabled: false

    useHelmHooks: true

    podSecurityContext: {}
      # fsGroup: 2000

    securityContext:
      # capabilities:
      #   drop:
      #   - ALL
      # readOnlyRootFilesystem: true
      # runAsNonRoot: true
      runAsUser: 0

    resources: {}
      # limits:
      #   cpu: 100m
      #   memory: 128Mi
      # requests:
      #   cpu: 100m
      #   memory: 128Mi

    nodeSelector: {}

    tolerations: []

    affinity: {}

    serviceAccount:
      # Specifies whether a service account should be created
      create: true
      # The name of the service account to use.
      # If not set and create is true, a name is generated using the fullname template
      name: ""

    rbac:
      enabled: true
      rules:
        - apiGroups:
            - ""
          resources:
            - "secrets"
          verbs:
            - "list"
            - "get"
            - "create"
            - "patch"


dashboard:
  enabled: true

  bootstrap:
    create: false
    name: "{{ $.Release.Name }}-bootstrap"

  secretRefs:
  - name: "LOKI_EVENTS_BASIC_AUTH_PASSWORD"
    secretName: "{{ $.Release.Name }}-loki-gateway-auth"
    secretKey: "dashboard-events"
  - name: "GRAFANA_BASIC_AUTH_USERNAME"
    secretName: "{{ $.Release.Name }}-drax-auth"
    secretKey: admin-username
  - name: "GRAFANA_BASIC_AUTH_PASSWORD"
    secretName: "{{ $.Release.Name }}-drax-auth"
    secretKey: admin-password
  - name: "KEYCLOAK_CLIENT_ID"
    secretName: "{{ $.Release.Name }}-auth-dashboard"
    secretKey: client-id
  - name: "KEYCLOAK_CLIENT_SECRET"
    secretName: "{{ $.Release.Name }}-auth-dashboard"
    secretKey: client-secret
  - name: "LOKI_LOGS_EXTERNAL_PASSWORD"
    secretName: "{{ $.Release.Name }}-loki-gateway-auth"
    secretKey: external-logs
  - name: "LOKI_EVENTS_EXTERNAL_PASSWORD"
    secretName: "{{ $.Release.Name }}-loki-gateway-auth"
    secretKey: external-events
  - name: "INFLUXDB_TOKEN"
    secretName: "drax-influxdb2-auth"
    secretKey: admin-token
  - name: "LOKI_LOGS_BASIC_AUTH_PASSWORD"
    secretName: "{{ $.Release.Name }}-loki-gateway-auth"
    secretKey: grafana-logs

  config:
    # Defined for server config.json
    keycloakURL: "http://{{ $.Release.Name }}-keycloak.{{ $.Release.Namespace }}/keycloak"
    keycloakRealm: "drax"
    kafkaURL: "{{ $.Release.Name }}-kafka.{{ $.Release.Namespace }}"
    networkStateMonitorHost: "{{ $.Release.Name }}-network-state-monitor.{{ $.Release.Namespace }}"
    svcMonitorHost: "{{ $.Release.Name }}-service-monitor.{{ $.Release.Namespace }}"
    svcOrchestratorHost: "{{ $.Release.Name }}-service-orchestrator.{{ $.Release.Namespace }}"
    configApiHost: "{{ $.Release.Name }}-config-api.{{ $.Release.Namespace }}"
    pcixAppPodName: "accelleran-drax-pci-010-pci-xapp-api"
    lokiHost: "{{ .Release.Name }}-loki-gateway.{{ $.Release.Namespace }}"
    lokiPort: "80"
    ksqldbPodName: "{{ $.Values.global.kubeIp }}"
    nodeApiURL: "{{ $.Values.global.domain | default $.Values.global.ipAddress }}"
    nodeApiPort: "80"
    grafanaHost: "{{ $.Release.Name }}-grafana.{{ $.Release.Namespace }}"
    grafanaApiPort: "80"
    # Defined for core-ui config.js
    grafanaNodePort: ""
    grafanaPathPrefix: "/grafana"
    accelleranProduct: "{{ $.Values.global.accelleranProduct }}"
    # Defined for environment variable DRAX_VERSION
    draxVersionConfigmap: "{{ $.Release.Name }}-version"
    # Used for connection to the Energy Saving Scheduler rApp API
    energySavingSchedulerRapp:
      service: "rapp-energy-saving-scheduler-xapp-api"
      port: "8888"
    influxHost: "{{ $.Release.Name }}-influxdb2.{{ $.Release.Namespace }}"
    influxPort: "80"

  extraEnvs:
  - name: "LOKI_EVENTS_BASIC_AUTH_USERNAME"
    value: "dashboard-events"
  - name: "LOKI_LOGS_EXTERNAL_USERNAME"
    value: "external-logs"
  - name: "LOKI_EVENTS_EXTERNAL_USERNAME"
    value: "external-events"
  - name: "LOKI_LOGS_BASIC_AUTH_USERNAME"
    value: "grafana-logs"

  service:
    type: ClusterIP
    ports:
      http:
        port: 5000

  ingress:
    enabled: true
    className: drax
    annotations:
      nginx.ingress.kubernetes.io/auth-url: "https://$host/oauth2/auth"
      nginx.ingress.kubernetes.io/auth-signin: "https://$host/oauth2/start?rd=$escaped_request_uri"
      nginx.ingress.kubernetes.io/proxy-body-size: 30m
      nginx.ingress.kubernetes.io/proxy-buffer-size: 256k
      nginx.ingress.kubernetes.io/proxy-buffering: 'on'
      nginx.ingress.kubernetes.io/proxy-buffers-number: '4'
      nginx.ingress.kubernetes.io/proxy-max-temp-file-size: 1024m
    hosts:
      - paths:
          - path: /
            pathType: Prefix
            port: http
    tls: []


network-state-monitor:
  # Enable/disable installation of the Network State Monitor
  enabled: true

  config:
    core_agent_available: false

  bootstrap:
    create: false
    name: "{{ $.Release.Name }}-bootstrap"

  ingress:
    enabled: true
    className: drax
    annotations:
      nginx.ingress.kubernetes.io/use-regex: "true"
      nginx.ingress.kubernetes.io/rewrite-target: /$2
      nginx.ingress.kubernetes.io/auth-url: "https://$host/oauth2/auth"
      nginx.ingress.kubernetes.io/proxy-body-size: 30m
      nginx.ingress.kubernetes.io/proxy-buffer-size: 256k
      nginx.ingress.kubernetes.io/proxy-buffering: 'on'
      nginx.ingress.kubernetes.io/proxy-buffers-number: '4'
      nginx.ingress.kubernetes.io/proxy-max-temp-file-size: 1024m
    hosts:
      - paths:
          - path: /network-state-monitor(/|$)(.*)
            pathType: ImplementationSpecific
            port: http
    tls: []


service-monitor:
  # Enable/disable installation of the Service Monitor
  enabled: true

  monitoredNamespaces: "{{ .Release.Namespace }}"

  ingress:
    enabled: true
    className: drax
    annotations:
      nginx.ingress.kubernetes.io/use-regex: "true"
      nginx.ingress.kubernetes.io/rewrite-target: /$2
      nginx.ingress.kubernetes.io/auth-url: "https://$host/oauth2/auth"
      nginx.ingress.kubernetes.io/proxy-body-size: 30m
      nginx.ingress.kubernetes.io/proxy-buffer-size: 256k
      nginx.ingress.kubernetes.io/proxy-buffering: 'on'
      nginx.ingress.kubernetes.io/proxy-buffers-number: '4'
      nginx.ingress.kubernetes.io/proxy-max-temp-file-size: 1024m
    hosts:
      - paths:
          - path: /service-monitor(/|$)(.*)
            pathType: ImplementationSpecific
            port: http
    tls: []


service-orchestrator:
  # Enable/disable installation of the Service Orchestrator
  enabled: true

  kubeIp: "{{ .Values.global.kubeIp }}"

  ingress:
    enabled: true
    className: drax
    annotations:
      nginx.ingress.kubernetes.io/use-regex: "true"
      nginx.ingress.kubernetes.io/rewrite-target: /$2
      nginx.ingress.kubernetes.io/auth-url: "https://$host/oauth2/auth"
      nginx.ingress.kubernetes.io/proxy-body-size: 30m
      nginx.ingress.kubernetes.io/proxy-buffer-size: 256k
      nginx.ingress.kubernetes.io/proxy-buffering: 'on'
      nginx.ingress.kubernetes.io/proxy-buffers-number: '4'
      nginx.ingress.kubernetes.io/proxy-max-temp-file-size: 1024m
    hosts:
      - paths:
          - path: /service-orchestrator(/|$)(.*)
            pathType: ImplementationSpecific
            port: http
    tls: []


config-api:
  enabled: true

  config:
    default_service_namespace_5g: "default"
    default_oran_namespace_4g: "default"
    service_monitor_host: "{{ .Release.Name }}-service-monitor.{{ .Release.Namespace }}"
    service_monitor_port: "80"

  extraEnvs:
    - name: ROOT_PATH
      value: /config-api

  ingress:
    enabled: true
    className: drax
    annotations:
      nginx.ingress.kubernetes.io/auth-url: "https://$host/oauth2/auth"
      nginx.ingress.kubernetes.io/proxy-body-size: 30m
      nginx.ingress.kubernetes.io/proxy-buffer-size: 256k
      nginx.ingress.kubernetes.io/proxy-buffering: 'on'
      nginx.ingress.kubernetes.io/proxy-buffers-number: '4'
      nginx.ingress.kubernetes.io/proxy-max-temp-file-size: 1024m
    hosts:
      - paths:
          - path: /config-api
            pathType: Prefix
            port: http
    tls: []


cell-wrapper:
  enabled: true

  bootstrap:
    create: false
    name: "{{ $.Release.Name }}-bootstrap"

  nats:
    enabled: false
  redis:
    enabled: false


du-metrics-server:
  enabled: true

  bootstrap:
    create: false
    name: "{{ $.Release.Name }}-bootstrap"

  du-metrics-server:
    config:
      kafkaPublishingEnabled: true
      topics:
        default: accelleran.drax.5g.du_metrics
        ue_kpis: accelleran.drax.5g.du_metrics.ue_mac
        rlc_tx_kpis: accelleran.drax.5g.du_metrics.ue_rlc_tx
        rlc_rx_kpis: accelleran.drax.5g.du_metrics.ue_rlc_rx

  influxdb:
    nameOverride: "du-influxdb"

    adminUser:
      organization: "accelleran"
      bucket: "default"
      retention_policy: "0s"
      user: "admin"
      password: ""
      token: ""
      existingSecret: drax-du-influxdb-auth

    persistence:
      enabled: true
      accessMode: ReadWriteOnce
      size: 2Gi

    service:
      annotations: {}
      labels: {}
      type: ClusterIP
      portName: http
      port: 80
      targetPort: 8086


telemetry-collector:
  enabled: true
  service:
    enabled: true
    name: ""
    type: ClusterIP
    ports:
      udp:
        port: 55555
        targetPort: 55555
        protocol: UDP
      http:
        port: 9020
        targetPort: 9020
        protocol: TCP

  grafanaWebhookUrl: "http://{{ $.Release.Name }}-telemetry-collector.{{ $.Release.Namespace }}:9020/alert"

  influxdbAuthSecret: "drax-influxdb2-auth"

  config:
    internal:
      kafka:
        url: "{{ $.Release.Name }}-kafka.{{ $.Release.Namespace }}:9092"
      influxDB:
        url: "http://{{ $.Release.Name }}-influxdb2.{{ $.Release.Namespace }}:80"
        org: "accelleran"
    pipelines:
      - name: "cu_measurements"
        component: "cu"
        vendor: "accelleran"
        enabled: "true"
        consumers:
          natsConsumer:
            url: "{{ $.Release.Name }}-nats.{{ $.Release.Namespace }}:4222"
            subjects: "*.5G_MEAS_INFO.*.*.*.*"
        publishers:
          # kafkaPublisher:
          #   topic: "accelleran.drax.5g.ric.o1.ves"
          influxPublisher:
            defaultBucket: "meas5g"
            buckets:
              RrcMeasurementReport: "rrc_measurements"
      - name: "pm_counters"
        component: "cu"
        vendor: "accelleran"
        enabled: "true"
        consumers:
          natsConsumer:
            url: "{{ $.Release.Name }}-nats.{{ $.Release.Namespace }}:4222"
            subjects: "*.CUCP_COUNTERS_INFO,*.CUUP_COUNTERS_INFO"
        publishers:
          # kafkaPublisher:
          #   topic: "accelleran.drax.5g.ric.o1.ves"
          influxPublisher:
            defaultBucket: "default_performance_metrics"
            buckets:
              RRCConnEstabAtt: "rrc_connection_metrics"
              RRCConnEstabSucc: "rrc_connection_metrics"
              RRCConnReestabAtt: "rrc_connection_metrics"
              RRCConnReestabSucc: "rrc_connection_metrics"
              MMHoExeIntraReq: "handover_and_mobility_metrics"
              MMHoExeIntraSucc: "handover_and_mobility_metrics"
              RRCConnMean: "rrc_connection_metrics"
              RRCConnMax: "rrc_connection_metrics"
              SMPDUSessionSetupReq: "pdu_session_management_metrics"
              SMPDUSessionSetupReqSnssai: "pdu_session_management_metrics"
              SMPDUSessionSetupFail: "pdu_session_management_metrics"
              L1MSSRSRP: "rrc_measurements"
              MMHoPrepInterReq: "handover_and_mobility_metrics"
              MMHoPrepInterSucc: "handover_and_mobility_metrics"
              MMHoPrepInterFail: "handover_and_mobility_metrics"
              MMHoResAlloInterReq: "handover_and_mobility_metrics"
              MMHoResAlloInterSucc: "handover_and_mobility_metrics"
              MMHoResAlloInterFail: "handover_and_mobility_metrics"
              MMHoExeInterReq: "handover_and_mobility_metrics"
              AccDRBEstabAtt5QiSnssai: "radio_resource_utilization_metrics"
              DRBEstabSuccSnssai: "radio_resource_utilization_metrics"
              DRBEstabSucc5Qi: "radio_resource_utilization_metrics"
              DRBRelActNbr5QiSnssai: "radio_resource_utilization_metrics"
              DRBRelActNbrSnssai: "radio_resource_utilization_metrics"
              DRBRelActNbr5Qi: "radio_resource_utilization_metrics"
              MMHoExeInterReqTimeMean: "handover_and_mobility_metrics"
              MMHoExeInterReqTimeMax: "handover_and_mobility_metrics"
              AccGTPThpDl: "throughput_metrics"
              AccGTPThpDlQfiSnssaiPlmn: "throughput_metrics"
              AccGTPThpUl: "throughput_metrics"
              AccGTPThpUlQfiSnssaiPlmn: "throughput_metrics"
              AccDRBPdcpSduDelayDlQfiSnssaiPlmn: "radio_resource_utilization_metrics"
              AccDRBF1UPacketLossRateUlQoS: "radio_resource_utilization_metrics"
              AccDRBF1UPacketLossRateUlQfiSnssaiPlmn: "radio_resource_utilization_metrics"
              AccDRBF1UPacketLossRateUlSnssai: "radio_resource_utilization_metrics"
              AccDRBPdcpPacketDropRateDlQoS: "radio_resource_utilization_metrics"
              AccDRBPdcpPacketDropRateDlSnssai: "radio_resource_utilization_metrics"
              AccDRBPdcpPacketDropRateDlQfiSnssaiPlmn: "radio_resource_utilization_metrics"
              DRBPdcpSduDelayDlQoS: "radio_resource_utilization_metrics"
              DRBPdcpSduDelayDlSnssai: "radio_resource_utilization_metrics"
              DRBPdcpSduDelayDlDistQos: "radio_resource_utilization_metrics"
              DRBPdcpSduDelayDlDist: "radio_resource_utilization_metrics"
              DRBPdcpSduDelayDlDistSnssai: "radio_resource_utilization_metrics"
              AccDRBPdcpSduDelayDlDistQfiSnssaiPlmn: "radio_resource_utilization_metrics"
              AccDRBEstabSucc5QiSnssai: "radio_resource_utilization_metrics"
              DRBEstabAttSnssai: "radio_resource_utilization_metrics"
              DRBEstabAtt5Qi: "radio_resource_utilization_metrics"
      - name: "acc_du_v3"
        component: "du"
        vendor: "accelleran"
        enabled: "true"
        consumers:
          udpConsumer:
            port: "55555"
        publishers:
          # kafkaPublisher:
          #   topic: "accelleran.drax.5g.ric.o1.ves"
          influxPublisher:
            defaultBucket: "acc_du"
            buckets:
              DUUEMeasurements: "du_ue_measurements"
              DURLCMeasurements: "du_rlc_measurements"
      - name: "cu_events"
        component: "cu"
        vendor: "accelleran"
        enabled: "true"
        consumers:
          natsConsumer:
            url: "{{ $.Release.Name }}-nats.{{ $.Release.Namespace }}:4222"
            subjects: "*.F1-SCTP-ASSOC-FAILURE-IND"
        publishers:
          kafkaPublisher:
            topic: "accelleran.drax.5g.ric.o1.ves"
      - name: "grafana_alerts"
        component: "drax"
        vendor: "accelleran"
        enabled: "true"
        consumers:
          restConsumer:
            endpoint: "/alert"
            port: "9020"
        publishers:
          kafkaPublisher:
            topic: "accelleran.drax.5g.ric.o1.ves"

e2-t:
  enabled: true

  numOfE2Nodes: 2

  bootstrap:
    create: false
    name: "{{ $.Release.Name }}-bootstrap"


pm-counters:
  enabled: true

  ingress:
    enabled: true
    className: drax
    annotations:
      nginx.ingress.kubernetes.io/use-regex: "true"
      nginx.ingress.kubernetes.io/rewrite-target: /$2
      nginx.ingress.kubernetes.io/auth-url: "https://$host/oauth2/auth"
      nginx.ingress.kubernetes.io/proxy-body-size: 30m
      nginx.ingress.kubernetes.io/proxy-buffer-size: 256k
      nginx.ingress.kubernetes.io/proxy-buffering: 'on'
      nginx.ingress.kubernetes.io/proxy-buffers-number: '4'
      nginx.ingress.kubernetes.io/proxy-max-temp-file-size: 1024m
    hosts:
      - paths:
          - path: /pm-counters(/|$)(.*)
            pathType: ImplementationSpecific
            port: http
    tls: []


golang-nkafka-5g:
  mode: "5g"

  bootstrap:
    create: false
    name: "{{ $.Release.Name }}-bootstrap"

  config:
    natsConnectionParameters:
      connectTimeout: 5000
      maxReconnects: 120
      reconnectWait: 5000

    natsKafkaTopics:
      override: false
      # defaultKafkaTopic: "accelleran.drax.5g.ric.raw.messages"
      # translations:
      #   - natsSubject: "5G_CUUP_BEACON_INFO"
      #     kafkaTopic: "accelleran.drax.5g.ric.raw.cu_state"
      #   - natsSubject: "PM-REPORT-COUNTERS"
      #     kafkaTopic: "accelleran.drax.5g.ric.raw.pm_counters"
      #   ...


kafka:
  enabled: true

  global:
    storageClass: ""

  nameOverride: ""
  fullnameOverride: ""

  clusterDomain: cluster.local

  extraEnvVars:
    - name: "KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE"
      value: "true"

  extraConfigYaml:
    log.retention.ms: 604800000  # 7d
    log.retention.bytes: 4294967296  # 4GiB
    log.roll.ms: 86400000  # 24h
    log.segment.bytes: 268435456  # 0.25GiB

    log.local.retention.ms: 604800000  # 7d
    log.local.retention.bytes: 4294967296  # 4GiB

  listeners:
    client:
      name: CLIENT
      containerPort: 9092
      protocol: PLAINTEXT
    controller:
      name: CONTROLLER
      containerPort: 9093
      protocol: PLAINTEXT
    interbroker:
      name: INTERNAL
      containerPort: 9094
      protocol: PLAINTEXT
    external:
      name: EXTERNAL
      containerPort: 9095
      protocol: PLAINTEXT

  kraft:
    enabled: true

  controller:
    replicaCount: 3
    automountServiceAccountToken: true
    nodeSelector: {}
    persistence:
      size: 5Gi
    resourcesPreset: medium

  broker:
    automountServiceAccountToken: true
    nodeSelector: {}
    persistence:
      size: 5Gi
    resourcesPreset: medium

  provisioning:
    enabled: true
    automountServiceAccountToken: true
    nodeSelector: {}
    replicationFactor: 1
    numPartitions: 1
    topics:
      - name: kafka-cluster-init
        partitions: 1
        replicationFactor: 1
      - name: accelleran.drax.5g.ric.o1.ves
        partitions: 1
        replicationFactor: 1
      - name: accelleran.drax.5g.ric.raw.pm_counters
        partitions: 1
        replicationFactor: 1
      - name: accelleran.drax.5g.ric.raw.messages
        partitions: 1
        replicationFactor: 1
      - name: accelleran.drax.5g.du_metrics.ue_mac
        partitions: 1
        replicationFactor: 1
      - name: accelleran.drax.5g.ric.raw.cu_state
        partitions: 1
        replicationFactor: 1
      - name: accelleran.drax.5g.ric.raw.ue_measurements
        partitions: 1
        replicationFactor: 1
      - name: accelleran.drax.5g.du_metrics.ue_rlc_rx
        partitions: 1
        replicationFactor: 1
      - name: accelleran.drax.5g.du_metrics.ue_rlc_tx
        partitions: 1
        replicationFactor: 1
      - name: accelleran.drax.5g.ric.raw.ran_control_response
        partitions: 1
        replicationFactor: 1

  service:
    type: NodePort

    ports:
      client: 9092
      external: 9095
    nodePorts:
      client: ""
      external: "31090"

  externalAccess:
    enabled: true
    controller:
      service:
        type: "NodePort"
        useHostIPs: true
    broker:
      service:
        type: "NodePort"
        useHostIPs: true
    autoDiscovery:
      enabled: true

  serviceAccount:
    create: true
    name: ""
    automountServiceAccountToken: true
    annotations: {}
  rbac:
    create: true

  metrics:
    kafka:
      enabled: false
      automountServiceAccountToken: true
      nodeSelector: {}

    jmx:
      enabled: true
      service:
        ports:
          metrics: 5556


nats:
  enabled: true

  global:
    labels:
      drax/technology: 5g
      drax/component-name: nats

  natsBox:
    enabled: false

  promExporter:
    enabled: true
    port: 7777

  service:
    enabled: true
    name: ""

    ports:
      nats:
        enabled: true
      monitor:
        enabled: true
    merge:
      spec:
        type: NodePort
        ports:
          - name: nats
            port: 4222
            nodePort: 31100

  extraResources:
    - apiVersion: v1
      kind: Service
      metadata:
        name:
          $tplYaml: >
            {{ printf "%s-prom-exporter" (include "nats.fullname" $) | quote }}
      spec:
        selector:
          $tplYaml: |
            {{ include "nats.selectorLabels" $ }}
        ports:
          - protocol: TCP
            port: 7777
            targetPort: 7777


redis:
  enabled: true

  commonLabels:
    drax/technology: 5g
    drax/component-name: redis

  architecture: standalone
  auth:
    enabled: false
    usePasswordFiles: false

  master:
    nodeSelector: {}
    persistence:
      size: 1Gi
  replica:
    nodeSelector: {}


ingress-nginx:
  # enabled: true

  controller:
    watchIngressWithoutClass: false
    ingressClassResource:
      enabled: true
      # No release name as there is no tpl here and also in most ingress resources of third-party helm charts.
      # The consequence is only 1 drax installation per kubernetes cluster by default.
      name: drax
      default: false

    service:
      # replaced with dRAX service to allow templating
      enabled: false

    config:
      proxy-busy-buffers-size: "256k"

  tcp: {}
    # "4222": "{{ $.Release.Namespace }}/{{ $.Release.Name }}-nats:4222"
    # "9092": "{{ $.Release.Namespace }}/{{ $.Release.Name }}-kafka:9095"


oauth2-proxy:
  # enabled: true

  strategy:
    type: Recreate

  config:
    existingSecret: "drax-oauth2-proxy"  # no tpl
    clientID: "oauth2-proxy"
    clientSecret: ""
    cookieSecret: ""

    configFile: |-
      http_address = "0.0.0.0:4180"
      reverse_proxy = true
      ssl_insecure_skip_verify = true

      provider = "oidc"
      provider_display_name = "Accelleran dRAX"
      oidc_issuer_url = "https://{{ $.Values.global.domain | default $.Values.global.ipAddress }}/keycloak/realms/drax"
      redirect_url = "/oauth2/callback"
      email_domains = [ "*" ]
      insecure_oidc_allow_unverified_email = true
      scope = "openid email profile"

      whitelist_domains = [ {{ with $.Values.global.domain }}"{{ . }}",".{{ . }}",{{ end }}"{{ $.Values.global.ipAddress }}" ]
      cookie_domains = [ {{ with $.Values.global.domain }}"{{ . }}",".{{ . }}",{{ end }}"{{ $.Values.global.ipAddress }}" ]

      cookie_csrf_per_request = true
      cookie_csrf_expire = "5m"

      skip_provider_button = true

      skip_jwt_bearer_tokens = true
      bearer_token_login_fallback = false

      api_routes = [
        "^/api"
      ]

  extraObjects:
    - apiVersion: networking.k8s.io/v1
      kind: Ingress
      metadata:
        name: "{{ $.Release.Name }}-oauth2-proxy"
        annotations:
          nginx.ingress.kubernetes.io/proxy-body-size: 30m
          nginx.ingress.kubernetes.io/proxy-buffer-size: 256k
          nginx.ingress.kubernetes.io/proxy-buffering: 'on'
          nginx.ingress.kubernetes.io/proxy-buffers-number: '4'
          nginx.ingress.kubernetes.io/proxy-max-temp-file-size: 1024m
      spec:
        ingressClassName: drax
        rules:
          - http:
              paths:
              - path: /oauth2
                pathType: Prefix
                backend:
                  service:
                    name: "{{ template \"oauth2-proxy.fullname\" . }}"
                    port:
                      number: 80
        tls:
          - {}


keycloak:
  # enabled: true

  auth:
    adminUser: "tmp"
    adminPassword: ""

    existingSecret: "{{ $.Release.Name }}-drax-auth"
    passwordSecretKey: "tmp-password"

  postgresql:
    nameOverride: "keycloak-postgresql"

    auth:
      postgresPassword: ""
      username: "accelleran-drax-keycloak"
      password: ""
      database: "accelleran-drax-keycloak"
      existingSecret: "{{ $.Release.Name }}-keycloak-postgresql"

  proxyHeaders: "xforwarded"
  httpRelativePath: "/keycloak/"

  ingress:
    # use ingress in extraDeploy as it allows to leave out the host
    enabled: false

  extraVolumes:
    - name: accelleran-drax-theme
      configMap:
        name: "{{ $.Release.Name }}-keycloak-theme-accelleran-drax"
        items:
          - key: common-resources-img-favicon.ico
            path: common/resources/img/favicon.ico
          - key: login-theme.properties
            path: login/theme.properties
          - key: login-resources-css-accelleran-drax-login.css
            path: login/resources/css/accelleran-drax-login.css
          - key: login-resources-img-accelleran-logo-white.svg
            path: login/resources/img/accelleran-logo-white.svg
          - key: login-resources-img-accelleran-drax-bg.jpg
            path: login/resources/img/accelleran-drax-bg.jpg

  extraVolumeMounts:
    - name: accelleran-drax-theme
      mountPath: /opt/bitnami/keycloak/themes/accelleran-drax/

  extraDeploy:
    - apiVersion: networking.k8s.io/v1
      kind: Ingress
      metadata:
        name: "{{ $.Release.Name }}-keycloak"
        annotations:
          nginx.ingress.kubernetes.io/proxy-body-size: 30m
          nginx.ingress.kubernetes.io/proxy-buffer-size: 256k
          nginx.ingress.kubernetes.io/proxy-buffering: 'on'
          nginx.ingress.kubernetes.io/proxy-buffers-number: '4'
          nginx.ingress.kubernetes.io/proxy-max-temp-file-size: 1024m
      spec:
        ingressClassName: drax
        rules:
          - http:
              paths:
              - path: /keycloak
                pathType: Prefix
                backend:
                  service:
                    name: "{{ $.Release.Name }}-keycloak"
                    port:
                      number: 80
        tls:
          - {}


prometheus:
  enabled: true
  nodeSelector: {}

  alertmanager:
    enabled: false

  prometheus-node-exporter:
    enabled: true

  prometheus-pushgateway:
    nodeSelector: {}

  kube-state-metrics:
    nodeSelector: {}

  serviceAccounts:
    kubeStateMetrics:
      create: true
      name: null
    nodeExporter:
      create: true
      name: null
    pushgateway:
      create: true
      name: null
    server:
      create: true
      name: null

  # Retention policy on the Prometheus storage
  server:
    name: server
    persistentVolume:
      enabled: true
      storageClassName: ""
      size: 2Gi
    statefulSet:
      enabled: true
      labels:
        drax/component-name: prometheus
        drax/role: ric

    podLabels:
      drax/component-name: prometheus-server
      drax/role: ric

    retention: 15d
    service:
      labels:
        drax/component-name: prometheus-server
        drax/role: ric
      type: NodePort
      nodePort: 30304

  # adds additional scrape configs to prometheus.yml
  # must be a string so you have to add a | after extraScrapeConfigs:
  extraScrapeConfigs: |
    - job_name: 5gPmCountersXapp
      scrape_interval: 2s
      static_configs:
        - targets:
          - "{{ $.Release.Name }}-pm-counters.{{ $.Release.Namespace }}:8000"
    - job_name: kafkaMonitoringJmx
      static_configs:
        - targets:
          - "{{ $.Release.Name }}-kafka-jmx-metrics.{{ $.Release.Namespace }}:5556"
    - job_name: kafkaMonitoringKminion
      static_configs:
        - targets:
          - "{{ $.Release.Name }}-kminion.{{ $.Release.Namespace }}:8080"
    - job_name: natsMonitoring
      static_configs:
        - targets:
          - "{{ $.Release.Name }}-nats-prom-exporter.{{ $.Release.Namespace }}:7777"


grafana:
  enabled: true
  nodeSelector: {}
  extraLabels:
    drax/role: ric
    drax/component-name: grafana

  initChownData:
    securityContext:
      capabilities:
        add:
          - CHOWN
          - DAC_READ_SEARCH
        drop:
          - ALL

  persistence:
    type: pvc
    enabled: true
    storageClassName: ""
    size: 1Gi

  service:
    enabled: true
    type: ClusterIP
    port: 80
    targetPort: 3000

  ingress:
    enabled: true
    ingressClassName: "drax"
    annotations:
      nginx.ingress.kubernetes.io/auth-url: "https://$host/oauth2/auth"
      nginx.ingress.kubernetes.io/auth-signin: "https://$host/oauth2/start?rd=$escaped_request_uri"
      nginx.ingress.kubernetes.io/proxy-body-size: 30m
      nginx.ingress.kubernetes.io/proxy-buffer-size: 256k
      nginx.ingress.kubernetes.io/proxy-buffering: 'on'
      nginx.ingress.kubernetes.io/proxy-buffers-number: '4'
      nginx.ingress.kubernetes.io/proxy-max-temp-file-size: 1024m
    labels: {}
    hosts: []
    path: /grafana
    pathType: Prefix
    extraPaths: []
    tls: []

  admin:
    existingSecret: "{{ $.Release.Name }}-drax-auth"
    userKey: "admin-username"
    passwordKey: "admin-password"

  grafana.ini:
    auth.basic:
      enabled: true
    auth.anonymous:
      enabled: true
      # Organization name that should be used for unauthenticated users
      org_name: Main Org.
      # Role for unauthenticated users, other valid values are `Editor` and `Admin`
      org_role: Viewer
    server:
      protocol: http
      domain: "0.0.0.0"
      http_port: 3000
      root_url: "/grafana/"
      serve_from_sub_path: true

  envRenderSecret:
    slack-token:
      value: "{{ $.Values.global.alerting.slackToken }}"
    alerting:
      value: "{{ $.Values.global.alerting.enabled }}"

  envValueFrom:
    DU_INFLUXDB_ADMIN_TOKEN:
      secretKeyRef:
        name: "drax-du-influxdb-auth"
        key: admin-token

    LOKI_LOGS_BASIC_AUTH_PASSWORD:
      secretKeyRef:
        name: "{{ $.Release.Name }}-loki-gateway-auth"
        key: grafana-logs

    LOKI_EVENTS_BASIC_AUTH_PASSWORD:
      secretKeyRef:
        name: "{{ $.Release.Name }}-loki-gateway-auth"
        key: grafana-events

    INFLUXDB2_ADMIN_TOKEN:
      secretKeyRef:
        name: "drax-influxdb2-auth"
        key: admin-token

    SLACK_TOKEN:
      secretKeyRef:
        name: "{{ $.Release.Name }}-slack-auth"
        key: slack-token

  env:
    GF_PANELS_DISABLE_SANITIZE_HTML: false

  datasources:
    datasources.yaml:
      apiVersion: 1
      datasources:
        - access: proxy
          isDefault: true
          name: Prometheus
          type: prometheus
          url: http://{{ .Release.Name }}-prometheus-server.{{ .Release.Namespace }}:80
          jsonData:
            timeInterval: 2s
        - access: proxy
          isDefault: false
          name: Loki-Logs
          type: loki
          url: http://{{ .Release.Name }}-loki-gateway.{{ .Release.Namespace }}:80
          uid: P8E80F9AEF21F6940
          basicAuth: true
          basicAuthUser: grafana-logs
          secureJsonData:
            basicAuthPassword: ${LOKI_LOGS_BASIC_AUTH_PASSWORD}
          jsonData:
            manageAlerts: false
        - access: proxy
          isDefault: false
          name: Loki-Events
          type: loki
          url: http://{{ .Release.Name }}-loki-gateway.{{ .Release.Namespace }}:80
          basicAuth: true
          basicAuthUser: grafana-events
          secureJsonData:
            basicAuthPassword: ${LOKI_EVENTS_BASIC_AUTH_PASSWORD}
          jsonData:
            manageAlerts: false
        - access: proxy
          isDefault: false
          name: InfluxDB-4G
          type: influxdb
          url: http://{{ .Release.Name }}-influxdb.{{ .Release.Namespace }}:8086
          user: admin
          password: password
          database: db_4G
          basicAuth: true
          basicAuthUser: admin
          basicAuthPassword: password
        - access: proxy
          isDefault: false
          name: InfluxDB-5G
          type: influxdb
          url: http://{{ .Release.Name }}-influxdb.{{ .Release.Namespace }}:8086
          user: admin
          password: password
          database: db_5G
          basicAuth: true
          basicAuthUser: admin
          basicAuthPassword: password
        - name: InfluxDB-DU
          type: influxdb
          access: proxy
          url: "http://{{ $.Release.Name }}-du-influxdb.{{ $.Release.Namespace }}:80"
          uid: JOSE3g9KVz
          secureJsonData:
            token: ${DU_INFLUXDB_ADMIN_TOKEN}
          jsonData:
            version: Flux
            organization: accelleran
            defaultBucket: default
            tlsSkipVerify: true
        - name: InfluxDB2
          type: influxdb
          access: proxy
          url: "http://{{ $.Release.Name }}-influxdb2.{{ $.Release.Namespace }}:80"
          uid: ddswjfzs92bk0b
          secureJsonData:
            token: ${INFLUXDB2_ADMIN_TOKEN}
          jsonData:
            version: Flux
            organization: accelleran
            defaultBucket: default
            tlsSkipVerify: true

  # Create and mount alerting configuration for the rules, contactpoints and the policies
  alertingConfigMaps:
    contactpoints: "{{ .Release.Name }}-grafana-contactpoints"
    rules: "{{ .Release.Name }}-grafana-rules"
    policies: "{{ .Release.Name }}-grafana-policies"

  extraContainerVolumes:
    - name: contactpoints-config
      configMap:
        name: "{{ .Release.Name }}-grafana-contactpoints"
    - name: rules-config
      configMap:
        name: "{{ .Release.Name }}-grafana-rules"
    - name: policies-config
      configMap:
        name: "{{ .Release.Name }}-grafana-policies"

  extraVolumeMounts:
    - name: contactpoints-config
      mountPath: /etc/grafana/provisioning/alerting/contactpoints.yaml
      subPath: contactpoints.yaml
      readOnly: true
    - name: rules-config
      mountPath: /etc/grafana/provisioning/alerting/rules.yaml
      subPath: rules.yaml
      readOnly: true
    - name: policies-config
      mountPath: /etc/grafana/provisioning/alerting/policies.yaml
      subPath: policies.yaml
      readOnly: true

  dashboardProviders:
    dashboardproviders.yaml:
      apiVersion: 1
      providers:
        # - name: "4g-monitoring-dashboard"
        #   orgId: 1
        #   folder: ""
        #   type: file
        #   disableDeletion: false
        #   editable: true
        #   options:
        #     path: /var/lib/grafana/dashboards/4g-monitoring-dashboard
        # - name: "custom-dashboard"
        #   orgId: 1
        #   folder: ""
        #   type: file
        #   disableDeletion: false
        #   editable: true
        #   options:
        #     path: /var/lib/grafana/dashboards/custom-dashboard
        - name: "loki-log-dashboard"
          orgId: 1
          folder: ""
          type: file
          disableDeletion: false
          editable: true
          options:
            path: /var/lib/grafana/dashboards/loki-log-dashboard
        # - name: "5g-health-dashboard"
        #   orgId: 1
        #   folder: ""
        #   type: file
        #   disableDeletion: false
        #   editable: true
        #   options:
        #     path: /var/lib/grafana/dashboards/5g-health-dashboard
        - name: "5g-monitoring-dashboard"
          orgId: 1
          folder: ""
          type: file
          disableDeletion: false
          editable: true
          options:
            path: /var/lib/grafana/dashboards/5g-monitoring-dashboard
        - name: "5g-monitoring-dashboard-5m"
          orgId: 1
          folder: ""
          type: file
          disableDeletion: false
          editable: true
          options:
            path: /var/lib/grafana/dashboards/5g-monitoring-dashboard-5m
        - name: "5g-cucp-pm-counters"
          orgId: 1
          folder: ""
          type: file
          disableDeletion: false
          editable: true
          options:
            path: /var/lib/grafana/dashboards/5g-cucp-pm-counters
        - name: "5g-cucp-pm-counters-5m"
          orgId: 1
          folder: ""
          type: file
          disableDeletion: false
          editable: true
          options:
            path: /var/lib/grafana/dashboards/5g-cucp-pm-counters-5m
        - name: "5g-cuup-pm-counters"
          orgId: 1
          folder: ""
          type: file
          disableDeletion: false
          editable: true
          options:
            path: /var/lib/grafana/dashboards/5g-cuup-pm-counters
        - name: "5g-cuup-pm-counters-5m"
          orgId: 1
          folder: ""
          type: file
          disableDeletion: false
          editable: true
          options:
            path: /var/lib/grafana/dashboards/5g-cuup-pm-counters-5m
        - name: "5g-du-metrics"
          orgId: 1
          folder: ""
          type: file
          disableDeletion: false
          editable: true
          options:
            path: /var/lib/grafana/dashboards/5g-du-metrics
        - name: "kafka-cluster-monitoring"
          orgId: 1
          folder: ""
          type: file
          disableDeletion: false
          editable: true
          options:
            path: /var/lib/grafana/dashboards/kafka-cluster-monitoring
        - name: "nats-dashboard"
          orgId: 1
          folder: ""
          type: file
          disableDeletion: false
          editable: true
          options:
            path: /var/lib/grafana/dashboards/nats-dashboard

  dashboardsConfigMaps:
    # 4g-monitoring-dashboard: "{{ .Release.Name }}-grafana-4g-monitoring-dashboard"
    # custom-dashboard: "{{ .Release.Name }}-grafana-custom-dashboard"
    loki-log-dashboard: "{{ .Release.Name }}-grafana-loki-log-dashboard"
    # 5g-health-dashboard: "{{ .Release.Name }}-grafana-5g-health-dashboard"
    5g-monitoring-dashboard: "{{ .Release.Name }}-grafana-5g-monitoring-dashboard"
    5g-monitoring-dashboard-5m: "{{ .Release.Name }}-grafana-5g-monitoring-dashboard-5m"
    5g-cucp-pm-counters: "{{ .Release.Name }}-grafana-5g-cucp-pm-counters"
    5g-cuup-pm-counters: "{{ .Release.Name }}-grafana-5g-cuup-pm-counters"
    5g-cucp-pm-counters-5m: "{{ .Release.Name }}-grafana-5g-cucp-pm-counters-5m"
    5g-cuup-pm-counters-5m: "{{ .Release.Name }}-grafana-5g-cuup-pm-counters-5m"
    5g-du-metrics: "{{ .Release.Name }}-grafana-5g-du-metrics"
    kafka-cluster-monitoring: "{{ .Release.Name }}-grafana-kafka-cluster-monitoring"
    nats-dashboard: "{{ .Release.Name }}-grafana-nats-dashboard"

  testFramework:
    enabled: false


loki-gateway:
  # enabled: true

  persistentLogLevel: warning

  auth:
    enabled: true
    preventSecretUninstall: true
    users:
      - username: "promtail-logs"
        password: ""
        organization: "logs"
      - username: "grafana-logs"
        password: ""
        organization: "logs"
      - username: "promtail-events"
        password: ""
        organization: "events"
      - username: "grafana-events"
        password: ""
        organization: "events"
      - username: "dashboard-events"
        password: ""
        organization: "events"
      - username: "loki-deleter-logs"
        password: ""
        organization: "logs"
      - username: "external-logs"
        password: ""
        organization: "logs"
      - username: "external-events"
        password: ""
        organization: "events"

  service:
    type: NodePort
    ports:
      http:
        port: 80
        targetPort: 8080
        nodePort: 31000

  ingress:
    enabled: false
    className: ""
    annotations: {}
    hosts:
      -
        # host: example.local
        paths:
          - path: /
            pathType: ImplementationSpecific
            port: http
    tls: []
    #  - secretName: chart-example-tls
    #    hosts:
    #      - chart-example.local


loki:
  # enabled: true

  loki:
    overrideConfiguration:
      table_manager:
        retention_deletes_enabled: true
        retention_period: 672h  # 28d
      limits_config:
        max_query_lookback: 672h  # 28 days
        retention_period: 672h  # 28d
        max_entries_limit_per_query: 10000
      compactor:
        retention_enabled: true
        compaction_interval: 10m
        delete_request_store: s3
        delete_request_cancel_period: 1m
        retention_delete_delay: 1m
      runtime_config:
        file: "/runtime-config/tenants.yaml"

      schema_config:
        configs:
          - from: "2024-04-01"
            store: tsdb
            object_store: s3
            schema: v13
            index:
              prefix: loki_index_
              period: 24h
      ingester:
        chunk_encoding: snappy
      tracing:
        enabled: true
      querier:
        max_concurrent: 4

      common:
        storage:
          s3:
            endpoint: ${MINIO_ENDPOINT}
            bucketnames: chunks
            access_key_id: ${MINIO_ACCESS_KEY_ID}
            secret_access_key: ${MINIO_SECRET_ACCESS_KEY}
            s3forcepathstyle: true
            insecure: true

  compactor:
    replicaCount: 1
    updateStrategy:
      type: Recreate
    resourcesPreset: "none"
    extraArgs:
    - -config.expand-env=true
    extraEnvVars:
      - name: MINIO_ENDPOINT
        value: "{{ $.Release.Name }}-minio.{{ $.Release.Namespace }}.svc:9000"
      - name: MINIO_ACCESS_KEY_ID
        valueFrom:
          secretKeyRef:
            name: "{{ $.Release.Name }}-minio"
            key: rootUser
      - name: MINIO_SECRET_ACCESS_KEY
        valueFrom:
          secretKeyRef:
            name: "{{ $.Release.Name }}-minio"
            key: rootPassword
    extraVolumes:
      - name: loki-tenants
        configMap:
          name: "{{ $.Release.Name }}-drax-loki-tenants"
    extraVolumeMounts:
      - name: loki-tenants
        mountPath: "/runtime-config"

  indexGateway:
    resourcesPreset: "none"
    extraArgs:
    - -config.expand-env=true
    extraEnvVars:
      - name: MINIO_ENDPOINT
        value: "{{ $.Release.Name }}-minio.{{ $.Release.Namespace }}.svc:9000"
      - name: MINIO_ACCESS_KEY_ID
        valueFrom:
          secretKeyRef:
            name: "{{ $.Release.Name }}-minio"
            key: rootUser
      - name: MINIO_SECRET_ACCESS_KEY
        valueFrom:
          secretKeyRef:
            name: "{{ $.Release.Name }}-minio"
            key: rootPassword
    extraVolumes:
      - name: loki-tenants
        configMap:
          name: "{{ $.Release.Name }}-drax-loki-tenants"
    extraVolumeMounts:
      - name: loki-tenants
        mountPath: "/runtime-config"

  distributor:
    resourcesPreset: "none"
    extraArgs:
    - -config.expand-env=true
    extraEnvVars:
      - name: MINIO_ENDPOINT
        value: "{{ $.Release.Name }}-minio.{{ $.Release.Namespace }}.svc:9000"
      - name: MINIO_ACCESS_KEY_ID
        valueFrom:
          secretKeyRef:
            name: "{{ $.Release.Name }}-minio"
            key: rootUser
      - name: MINIO_SECRET_ACCESS_KEY
        valueFrom:
          secretKeyRef:
            name: "{{ $.Release.Name }}-minio"
            key: rootPassword
    extraVolumes:
      - name: loki-tenants
        configMap:
          name: "{{ $.Release.Name }}-drax-loki-tenants"
    extraVolumeMounts:
      - name: loki-tenants
        mountPath: "/runtime-config"

  ingester:
    resourcesPreset: "none"
    extraArgs:
    - -config.expand-env=true
    extraEnvVars:
      - name: MINIO_ENDPOINT
        value: "{{ $.Release.Name }}-minio.{{ $.Release.Namespace }}.svc:9000"
      - name: MINIO_ACCESS_KEY_ID
        valueFrom:
          secretKeyRef:
            name: "{{ $.Release.Name }}-minio"
            key: rootUser
      - name: MINIO_SECRET_ACCESS_KEY
        valueFrom:
          secretKeyRef:
            name: "{{ $.Release.Name }}-minio"
            key: rootPassword
    extraVolumes:
      - name: loki-tenants
        configMap:
          name: "{{ $.Release.Name }}-drax-loki-tenants"
    extraVolumeMounts:
      - name: loki-tenants
        mountPath: "/runtime-config"

  querier:
    resourcesPreset: "none"
    extraArgs:
    - -config.expand-env=true
    extraEnvVars:
      - name: MINIO_ENDPOINT
        value: "{{ $.Release.Name }}-minio.{{ $.Release.Namespace }}.svc:9000"
      - name: MINIO_ACCESS_KEY_ID
        valueFrom:
          secretKeyRef:
            name: "{{ $.Release.Name }}-minio"
            key: rootUser
      - name: MINIO_SECRET_ACCESS_KEY
        valueFrom:
          secretKeyRef:
            name: "{{ $.Release.Name }}-minio"
            key: rootPassword
    extraVolumes:
      - name: loki-tenants
        configMap:
          name: "{{ $.Release.Name }}-drax-loki-tenants"
    extraVolumeMounts:
      - name: loki-tenants
        mountPath: "/runtime-config"

  queryFrontend:
    resourcesPreset: "none"
    extraArgs:
    - -config.expand-env=true
    extraEnvVars:
      - name: MINIO_ENDPOINT
        value: "{{ $.Release.Name }}-minio.{{ $.Release.Namespace }}.svc:9000"
      - name: MINIO_ACCESS_KEY_ID
        valueFrom:
          secretKeyRef:
            name: "{{ $.Release.Name }}-minio"
            key: rootUser
      - name: MINIO_SECRET_ACCESS_KEY
        valueFrom:
          secretKeyRef:
            name: "{{ $.Release.Name }}-minio"
            key: rootPassword
    extraVolumes:
      - name: loki-tenants
        configMap:
          name: "{{ $.Release.Name }}-drax-loki-tenants"
    extraVolumeMounts:
      - name: loki-tenants
        mountPath: "/runtime-config"

  queryScheduler:
    resourcesPreset: "none"
    extraArgs:
    - -config.expand-env=true
    extraEnvVars:
      - name: MINIO_ENDPOINT
        value: "{{ $.Release.Name }}-minio.{{ $.Release.Namespace }}.svc:9000"
      - name: MINIO_ACCESS_KEY_ID
        valueFrom:
          secretKeyRef:
            name: "{{ $.Release.Name }}-minio"
            key: rootUser
      - name: MINIO_SECRET_ACCESS_KEY
        valueFrom:
          secretKeyRef:
            name: "{{ $.Release.Name }}-minio"
            key: rootPassword
    extraVolumes:
      - name: loki-tenants
        configMap:
          name: "{{ $.Release.Name }}-drax-loki-tenants"
    extraVolumeMounts:
      - name: loki-tenants
        mountPath: "/runtime-config"

  ruler:
    resourcesPreset: "none"
    extraArgs:
    - -config.expand-env=true
    extraEnvVars:
      - name: MINIO_ENDPOINT
        value: "{{ $.Release.Name }}-minio.{{ $.Release.Namespace }}.svc:9000"
      - name: MINIO_ACCESS_KEY_ID
        valueFrom:
          secretKeyRef:
            name: "{{ $.Release.Name }}-minio"
            key: rootUser
      - name: MINIO_SECRET_ACCESS_KEY
        valueFrom:
          secretKeyRef:
            name: "{{ $.Release.Name }}-minio"
            key: rootPassword
    extraVolumes:
      - name: loki-tenants
        configMap:
          name: "{{ $.Release.Name }}-drax-loki-tenants"
    extraVolumeMounts:
      - name: loki-tenants
        mountPath: "/runtime-config"

  tableManager:
    resourcesPreset: "none"
    extraArgs:
    - -config.expand-env=true
    extraEnvVars:
      - name: MINIO_ENDPOINT
        value: "{{ $.Release.Name }}-minio.{{ $.Release.Namespace }}.svc:9000"
      - name: MINIO_ACCESS_KEY_ID
        valueFrom:
          secretKeyRef:
            name: "{{ $.Release.Name }}-minio"
            key: rootUser
      - name: MINIO_SECRET_ACCESS_KEY
        valueFrom:
          secretKeyRef:
            name: "{{ $.Release.Name }}-minio"
            key: rootPassword
    extraVolumes:
      - name: loki-tenants
        configMap:
          name: "{{ $.Release.Name }}-drax-loki-tenants"
    extraVolumeMounts:
      - name: loki-tenants
        mountPath: "/runtime-config"

  gateway:
    enabled: false
    resourcesPreset: "none"

  grafanaalloy:
    enabled: false
    resourcesPreset: "none"

  volumePermissions:
    resourcesPreset: "none"

  memcachedchunks:
    resourcesPreset: "none"
  memcachedfrontend:
    resourcesPreset: "none"
  memcachedindexqueries:
    resourcesPreset: "none"
  memcachedindexwrites:
    resourcesPreset: "none"


loki-deleter:
  enabled: false

  config:
    namespace: "{{ $.Release.Namespace }}"

    log:
      level: info

    period: "20m"
    threshold: 80

    # the names depend on minio.replicas and minio.drivesPerNode
    pvcNames:
      - "{{ $.Release.Name }}-minio"

    localPath: "/opt/local-path-provisioner"

    loki:
      host: "{{ $.Release.Name }}-loki-gateway.{{ $.Release.Namespace }}"
      retentionPeriod: "672h"
      deletePeriod: "24h"

  extraEnvs:
    - name: LOKI_USERNAME
      value: loki-deleter-logs
    - name: LOKI_PASSWORD
      valueFrom:
        secretKeyRef:
          name: "{{ $.Release.Name }}-loki-gateway-auth"
          key: loki-deleter-logs


minio:
  # enabled: true

  replicas: 1
  # Minio requires 2 to 16 drives for erasure code (drivesPerNode * replicas)
  # https://docs.min.io/docs/minio-erasure-code-quickstart-guide
  # Since we only have 1 replica, that means 2 drives must be used.
  # But for now we want to limit the amount of storage used, so 1 drive.
  drivesPerNode: 1
  rootUser: ""
  rootPassword: ""

  # With 1 replica and 1 drive we need to run in standalone mode
  mode: standalone

  # Allow the address used by Loki to refer to Minio to be overridden
  address: null

  buckets:
    - name: chunks
      policy: none
      purge: false
    - name: ruler
      policy: none
      purge: false
    - name: admin
      policy: none
      purge: false

  resources:
    requests:
      cpu: 100m
      memory: 128Mi
  persistence:
    size: 5Gi
    annotations: {}

minioPostJob:
  enabled: false


promtail-logs:
  # enabled: true

  nameOverride: "promtail-logs"

  config:
    enabled: true
    clients:
      - url: http://{{ .Release.Name }}-loki-gateway.{{ .Release.Namespace }}:80/loki/api/v1/push
        tenant_id: logs
        basic_auth:
          username: promtail-logs
          password_file: /etc/promtail/secrets/password
    snippets:
      extraRelabelConfigs:
        # set drax.accelleran.com/persistent-log-level=info to store info and up, default warning
        - source_labels:
            - __meta_kubernetes_pod_label_drax_accelleran_com_persistent_log_level
          regex: ^;*([^;]+)(;.*)?$
          action: replace
          target_label: persistent_level
      pipelineStages:
        - cri: {}

        - regex:
            expression: '(?P<level>ERROR|error|Error|WARN|warn|Warn|WARNING|warning|Warning|INFO|info|Info|DEBUG|debug|Debug|TRACE|trace|Trace)'
        - labels:
            level:

        - template:
            source: "persistent_level"
            template: "{{ .Value | TrimSpace | default \"warning\" | ToLower }}"
        - replace:
            source: "persistent_level"
            expression: "^(warn)$"
            replace: "warning"
        - labels:
            persistent_level:

        - template:
            source: "level"
            template: "{{ .Value | TrimSpace | default \"unknown\" | ToLower }}"
        - replace:
            source: "level"
            expression: "^(warn)$"
            replace: "warning"
        - labels:
            level:

        - drop:
            source:
              - "level"
              - "persistent_level"
            expression: "(trace);(debug|info|warning|error|none)"
            drop_counter_reason: "trace level"
        - drop:
            source:
              - "level"
              - "persistent_level"
            expression: "(debug);(info|warning|error|none)"
            drop_counter_reason: "debug level"
        - drop:
            source:
              - "level"
              - "persistent_level"
            expression: "(info);(warning|error|none)"
            drop_counter_reason: "info level"
        - drop:
            source:
              - "level"
              - "persistent_level"
            expression: "(warning);(error|none)"
            drop_counter_reason: "warning level"
        - drop:
            source:
              - "level"
              - "persistent_level"
            expression: "(error);(none)"
            drop_counter_reason: "error level"

  extraVolumeMounts:
    - name: loki-gateway-password
      mountPath: /etc/promtail/secrets

  extraVolumes:
    - name: loki-gateway-password
      secret:
        secretName: "{{ $.Release.Name }}-loki-gateway-auth"
        items:
          - key: promtail-logs
            path: password


promtail-events:
  # enabled: true

  nameOverride: "promtail-events"

  daemonset:
    enabled: false
  deployment:
    enabled: true

  config:
    enabled: true
    clients:
      - url: http://{{ .Release.Name }}-loki-gateway.{{ .Release.Namespace }}:80/loki/api/v1/push
        tenant_id: events
        basic_auth:
          username: promtail-events
          password_file: /etc/promtail/secrets/password
    snippets:
      scrapeConfigs: |
        - job_name: kafka-events
          kafka:
            brokers:
              - {{ .Release.Name }}-kafka.{{ .Release.Namespace }}:9092
            topics:
              - "accelleran.drax.5g.ric.o1.ves"
            use_incoming_timestamp: true
            labels:
              job: kafka-events
              app: {{ .Release.Name }}-promtail-events
          pipeline_stages:
            - json:
                expressions:
                  domain: event.commonEventHeader.domain
                  eventId: event.commonEventHeader.eventId
                  eventName: event.commonEventHeader.eventName
                  lastEpochMicrosec: event.commonEventHeader.lastEpochMicrosec
                  priority: event.commonEventHeader.priority
                  reportingEntityName: event.commonEventHeader.reportingEntityName
                  sequence: event.commonEventHeader.sequence
                  sourceName: event.commonEventHeader.sourceName
                  startEpochMicrosec: event.commonEventHeader.startEpochMicrosec
                  stndDefinedNamespace: event.commonEventHeader.stndDefinedNamespace
                  version: event.commonEventHeader.version
                  vesEventListenerVersion: event.commonEventHeader.vesEventListenerVersion
                  notificationType: event.stndDefinedFields.data.notificationType
                drop_malformed: true
            - regex:
               expression: '^(?P<keep>notify(NewAlarm|ClearedAlarm|Event))$'
               source: notificationType
            - labels:
               keep:
            - drop:
               source: keep
               value: ''
            - labels:
                domain:
                eventId:
                eventName:
                lastEpochMicrosec:
                priority:
                reportingEntityName:
                sequence:
                sourceName:
                startEpochMicrosec:
                stndDefinedNamespace:
                version:
                vesEventListenerVersion:

  initContainer:
    - name: check-kafka
      # renovate:
      image: accelleran/acc-generic-img:0.9.1
      imagePullPolicy: IfNotPresent
      command:
      - /bin/sh
      - -c
      - |
        until kcat -b "${KAFKA_HOSTNAME}:${KAFKA_PORT}" -t kafka-cluster-init -C -o -1 -e
        do
          sleep 1
        done
        echo "$(date) Kafka ready"
      env:
      - name: KAFKA_HOSTNAME
        valueFrom:
          configMapKeyRef:
            key: KAFKA_HOSTNAME
            name: "{{ $.Release.Name }}-bootstrap"
      - name: KAFKA_PORT
        valueFrom:
          configMapKeyRef:
            key: KAFKA_PORT
            name: "{{ $.Release.Name }}-bootstrap"

  extraVolumeMounts:
    - name: loki-gateway-password
      mountPath: /etc/promtail/secrets

  extraVolumes:
    - name: loki-gateway-password
      secret:
        secretName: "{{ $.Release.Name }}-loki-gateway-auth"
        items:
          - key: promtail-events
            path: password


influxdb2:
  enabled: true

  podLabels:
    drax/role: ric
    drax/component-name: influxdb2

  adminUser:
    organization: "accelleran"
    bucket: "default"
    retention_policy: "0s"
    user: "admin"
    password: ""
    token: ""
    existingSecret: drax-influxdb2-auth

  persistence:
    enabled: true
    accessMode: ReadWriteOnce
    size: 2Gi

  service:
    type: NodePort
    nodePort: 31200

  resources:
    requests:
      cpu: "0"
      memory: "0"
    limits:
      cpu: "4"
      memory: "8Gi"

  influxdbDownsampling:
    enabled: true
    containerName: create-downsampling-flux-tasks
    accelleranLicense:
      enabled: false
    # renovate:
    image:
      repository: accelleran/acc-generic-img
      tag: "0.9.1"
      pullPolicy: IfNotPresent
    command:
      - /bin/bash
      - -c
      - |
        sleep 30
        echo "Creating downsampling tasks in InfluxDB2..."
        set -euo pipefail

        JOBS=(
          "rrc_measurements RrcMeasurementReport min"
          "rrc_connection_metrics RRCConnEstabAtt sum"
          "rrc_connection_metrics RRCConnEstabSucc sum"
          "rrc_connection_metrics RRCConnReestabAtt sum"
          "rrc_connection_metrics RRCConnReestabSucc sum"
          "rrc_connection_metrics RRCConnMean mean"
          "rrc_connection_metrics RRCConnMax max"
          "handover_and_mobility_metrics MMHoExeIntraReq sum"
          "handover_and_mobility_metrics MMHoExeIntraSucc sum"
          "handover_and_mobility_metrics MMHoExeInterReq sum"
          "handover_and_mobility_metrics MMHoExeInterReqTimeMean mean"
          "handover_and_mobility_metrics MMHoExeInterReqTimeMax max"
          "handover_and_mobility_metrics MMHoPrepInterReq sum"
          "handover_and_mobility_metrics MMHoPrepInterSucc sum"
          "handover_and_mobility_metrics MMHoPrepInterFail sum"
          "handover_and_mobility_metrics MMHoResAlloInterReq sum"
          "handover_and_mobility_metrics MMHoResAlloInterSucc sum"
          "handover_and_mobility_metrics MMHoResAlloInterFail sum"
          "pdu_session_management_metrics SMPDUSessionSetupReq sum"
          "pdu_session_management_metrics SMPDUSessionSetupReqSnssai sum"
          "pdu_session_management_metrics SMPDUSessionSetupFail sum"
          "rrc_measurements L1MSSRSRP mean"
          "radio_resource_utilization_metrics AccDRBEstabAtt5QiSnssai sum"
          "radio_resource_utilization_metrics DRBEstabAttSnssai sum"
          "radio_resource_utilization_metrics DRBEstabAtt5Qi sum"
          "radio_resource_utilization_metrics DRBEstabSuccSnssai sum"
          "radio_resource_utilization_metrics DRBEstabSucc5Qi sum"
          "radio_resource_utilization_metrics DRBRelActNbrSnssai sum"
          "radio_resource_utilization_metrics DRBRelActNbr5Qi sum"
          "radio_resource_utilization_metrics DRBRelActNbr5QiSnssai sum"
          "radio_resource_utilization_metrics AccDRBPdcpSduDelayDlQoS mean"
          "radio_resource_utilization_metrics DRBPdcpSduDelayDlQoS mean"
          "radio_resource_utilization_metrics AccDRBPdcpPacketDropRateDlQoS mean"
          "radio_resource_utilization_metrics AccDRBPdcpPacketDropRateDlSnssai mean"
          "radio_resource_utilization_metrics AccDRBPdcpPacketDropRateDlQfiSnssaiPlmn mean"
          "radio_resource_utilization_metrics AccDRBF1UPacketLossRateUlQoS mean"
          "radio_resource_utilization_metrics AccDRBF1UPacketLossRateUlSnssai mean"
          "radio_resource_utilization_metrics AccDRBF1UPacketLossRateUlQfiSnssaiPlmn mean"
          "radio_resource_utilization_metrics AccDRBPdcpSduDelayDlQfiSnssaiPlmn mean"
          "radio_resource_utilization_metrics DRBPdcpSduDelayDlSnssai mean"
          "radio_resource_utilization_metrics DRBPdcpSduDelayDlDist sum"
          "radio_resource_utilization_metrics DRBPdcpSduDelayDlDistSnssai sum"
          "radio_resource_utilization_metrics DRBPdcpSduDelayDlDistQos sum"
          "radio_resource_utilization_metrics AccDRBPdcpSduDelayDlDistQfiSnssaiPlmn sum"
          "throughput_metrics AccGTPThpDl mean"
          "throughput_metrics AccGTPThpDlQfiSnssaiPlmn mean"
          "throughput_metrics AccGTPThpUl mean"
          "throughput_metrics AccGTPThpUlQfiSnssaiPlmn mean")

        declare -A JOB_GROUPS

        for entry in "${JOBS[@]}"; do
          read -r BUCKET MEAS AGG <<<"$entry"
          KEY="${AGG}__${BUCKET}"
          JOB_GROUPS["$KEY"]+="$MEAS "
        done

        for AGG in min sum mean max; do
          echo "Processing aggregation: $AGG"

          for key in "${!JOB_GROUPS[@]}"; do
          if [[ $key == ${AGG}__* ]]; then
            BUCKET="${key#${AGG}__}"
            MEAS_LIST=${JOB_GROUPS[$key]}
            # Build regex from measurements
            MEAS_REGEX=$(echo "$MEAS_LIST" | xargs -n1 | sort -u | paste -sd '|' -)

            # Raw to 1m
            PAYLOAD=$(cat <<EOF
            {"org": "${ORG}","name": "downsample_${BUCKET}_${AGG}_to_1m","flux": "option task = {name: \"downsample_${BUCKET}_${AGG}_to_1m\", every: 1h}from(bucket: \"${BUCKET}\")|> range(start: -1h)|> filter(fn: (r) => r._measurement =~ /^(${MEAS_REGEX})$/)|> aggregateWindow(every: 1m, fn: ${AGG}, createEmpty: false)|> to(bucket: \"${BUCKET}_1m\", org: \"${ORG}\")"}
        EOF
          )

            echo "Creating task for bucket: $BUCKET, aggregation: $AGG, granularity 1m"
            echo "Measurements: $MEAS_REGEX"

            curl --request POST "${INFLUXDB_URL}/api/v2/tasks" \
            --header "Authorization: Token ${INFLUXDB_TOKEN}" \
            --header "Content-Type: application/json" \
            --data "$PAYLOAD"

            # Raw to 5m
            PAYLOAD=$(cat <<EOF
            {"org": "${ORG}","name": "downsample_${BUCKET}_${AGG}_to_5m","flux": "option task = {name: \"downsample_${BUCKET}_${AGG}_to_5m\", every: 1h}from(bucket: \"${BUCKET}\")|> range(start: -1h)|> filter(fn: (r) => r._measurement =~ /^(${MEAS_REGEX})$/)|> aggregateWindow(every: 5m, fn: ${AGG}, createEmpty: false)|> to(bucket: \"${BUCKET}_5m\", org: \"${ORG}\")"}
        EOF
          )

            echo "Creating task for bucket: $BUCKET, aggregation: $AGG, granularity 5m"
            echo "Measurements: $MEAS_REGEX"

            curl --request POST "${INFLUXDB_URL}/api/v2/tasks" \
            --header "Authorization: Token ${INFLUXDB_TOKEN}" \
            --header "Content-Type: application/json" \
            --data "$PAYLOAD"

            # Raw to 15m
            PAYLOAD=$(cat <<EOF
            {"org": "${ORG}","name": "downsample_${BUCKET}_${AGG}_to_15m","flux": "option task = {name: \"downsample_${BUCKET}_${AGG}_to_15m\", every: 1h}from(bucket: \"${BUCKET}\")|> range(start: -1h)|> filter(fn: (r) => r._measurement =~ /^(${MEAS_REGEX})$/)|> aggregateWindow(every: 15m, fn: ${AGG}, createEmpty: false)|> to(bucket: \"${BUCKET}_15m\", org: \"${ORG}\")"}
        EOF
          )

            echo "Creating task for bucket: $BUCKET, aggregation: $AGG, granularity 15m"
            echo "Measurements: $MEAS_REGEX"

            curl --request POST "${INFLUXDB_URL}/api/v2/tasks" \
            --header "Authorization: Token ${INFLUXDB_TOKEN}" \
            --header "Content-Type: application/json" \
            --data "$PAYLOAD"

          fi
        done
        done

        echo "All tasks created successfully!"

  initScripts:
    enabled: true
    scripts:
      init.sh: |+
        #!/bin/bash
        influx bucket create -n default_performance_metrics -o accelleran -r 24h
        influx bucket create -n default_performance_metrics_1m -o accelleran -r 18h
        influx bucket create -n default_performance_metrics_5m -o accelleran -r 7d
        influx bucket create -n default_performance_metrics_15m -o accelleran -r 28d
        influx bucket create -n rrc_measurements -o accelleran -r 24h
        influx bucket create -n rrc_measurements_1m -o accelleran -r 18h
        influx bucket create -n rrc_measurements_5m -o accelleran -r 7d
        influx bucket create -n rrc_measurements_15m -o accelleran -r 28d
        influx bucket create -n rrc_connection_metrics -o accelleran -r 24h
        influx bucket create -n rrc_connection_metrics_1m -o accelleran -r 18h
        influx bucket create -n rrc_connection_metrics_5m -o accelleran -r 7d
        influx bucket create -n rrc_connection_metrics_15m -o accelleran -r 28d
        influx bucket create -n handover_and_mobility_metrics -o accelleran -r 24h
        influx bucket create -n handover_and_mobility_metrics_1m -o accelleran -r 18h
        influx bucket create -n handover_and_mobility_metrics_5m -o accelleran -r 7d
        influx bucket create -n handover_and_mobility_metrics_15m -o accelleran -r 28d
        influx bucket create -n pdu_session_management_metrics -o accelleran -r 24h
        influx bucket create -n pdu_session_management_metrics_1m -o accelleran -r 18h
        influx bucket create -n pdu_session_management_metrics_5m -o accelleran -r 7d
        influx bucket create -n pdu_session_management_metrics_15m -o accelleran -r 28d
        influx bucket create -n radio_resource_utilization_metrics -o accelleran -r 24h
        influx bucket create -n radio_resource_utilization_metrics_1m -o accelleran -r 18h
        influx bucket create -n radio_resource_utilization_metrics_5m -o accelleran -r 7d
        influx bucket create -n radio_resource_utilization_metrics_15m -o accelleran -r 28d
        influx bucket create -n throughput_metrics -o accelleran -r 24h
        influx bucket create -n throughput_metrics_1m -o accelleran -r 18h
        influx bucket create -n throughput_metrics_5m -o accelleran -r 7d
        influx bucket create -n throughput_metrics_15m -o accelleran -r 28d
        influx bucket create -n du_ue_measurements -o accelleran -r 24h
        influx bucket create -n du_ue_measurements_1m -o accelleran -r 18h
        influx bucket create -n du_ue_measurements_5m -o accelleran -r 7d
        influx bucket create -n du_ue_measurements_15m -o accelleran -r 28d
        influx bucket create -n du_rlc_measurements -o accelleran -r 24h
        influx bucket create -n du_rlc_measurements_1m -o accelleran -r 18h
        influx bucket create -n du_rlc_measurements_5m -o accelleran -r 7d
        influx bucket create -n du_rlc_measurements_15m -o accelleran -r 28d
        influx bucket create -n energy_saving_scheduler -o accelleran -r 7d

kminion:
  enabled: true

  nodeSelector: {}

  kminion:
    # See reference config: https://github.com/cloudhut/kminion/blob/master/docs/reference-config.yaml
    config:
      kafka:
        brokers:
          - "{{ $.Release.Name }}-kafka.{{ $.Release.Namespace }}:9092"
        clientId: "kminion"
        retryInitConnection: true

      minion:
        consumerGroups:
          enabled: true
          scrapeMode: offsetsTopic
          granularity: partition
          allowedGroups: ["*"]
          ignoredGroups: []
        topics:
          granularity: partition
          allowedTopics: []
          ignoredTopics: []
          infoMetric:
            configKeys: ["cleanup.policy"]
        logDirs:
          enabled: false

      exporter:
        namespace: "kminion"
        host: ""
        port: 8080

      logger:
        level: info

  tests:
    enabled: false

extraResources: []
